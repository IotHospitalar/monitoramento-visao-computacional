# Monitoramento com Vis√£o Computacional

## Descri√ß√£o

Este projeto implementa um sistema de **detec√ß√£o de quedas** em v√≠deos, utilizando:

* **YOLO** (v11) para detec√ß√£o de pessoas
* **Deep SORT** para rastreamento de m√∫ltiplos objetos
* **InsightFace** (MXNet) para reconhecimento facial
* **EmotiEffLib** para reconhecimento de express√µes

O c√≥digo est√° organizado como um **pacote Python** denominado `reconhecimento` e fornece tr√™s funcionalidades principais:

1. **Captura de imagens** para gera√ß√£o do dataset de rostos
2. **Treinamento** em cima do dataset gerado
3. **Reconhecimento** em v√≠deos pr√©-existentes ou na webcam

## Estrutura de Pastas

O projeto est√° organizado da seguinte forma:

```
‚îú‚îÄ‚îÄ reconhecimento/             # C√≥digo-fonte do pacote Python
‚îú‚îÄ‚îÄ videos/                     # V√≠deos de entrada para reconhecimento
‚îú‚îÄ‚îÄ dataset/                    # Imagens brutas para enrollment
‚îÇ   ‚îú‚îÄ‚îÄ pessoa1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ img2.jpg
‚îÇ   ‚îî‚îÄ‚îÄ pessoa2.jpg
‚îú‚îÄ‚îÄ trainer/
‚îÇ   ‚îî‚îÄ‚îÄ face_db.pickle          # Banco de embeddings gerado
‚îú‚îÄ‚îÄ yolo11n.pt                  # Modelos YOLO pr√©-treinados
‚îú‚îÄ‚îÄ yolo8n.pt                   
‚îú‚îÄ‚îÄ requirements.txt            # Pacotes necess√°rios para rodar o c√≥digo
‚îî‚îÄ‚îÄ enet_b0_8_best_afew.pt      # Modelo EmotiEffLib pr√©-treinado
```

## Depend√™ncias

Certifique-se de ter instalado o Python 3.8+ e, de prefer√™ncia, um ambiente virtual.

```bash
pip install -r requirements.txt
```
ou
```bash
pip install ultralytics deep_sort_realtime opencv-python torch torchvision torchaudio insightface mxnet mediapipe matplotlib pillow numpy onnxruntime hsemotion-onnx
```

## Como Rodar

A partir do diret√≥rio raiz do projeto (aquele que cont√©m `reconhecimento/`), voc√™ pode executar o sistema de duas formas:

### 1. Modo n√£o interativo (via flags)

* **Capturar imagens para o dataset**:

  ```bash
  python -m reconhecimento --capture
  ```

* **Treinar o reconhecimento facial no dataset**:

  ```bash
  python -m reconhecimento --train
  ```

* **Executar reconhecimento**:

  * Em um arquivo espec√≠fico:

    ```bash
    python -m reconhecimento --recognize --video ./videos/nome_do_video.mp4 --model yolo11n.pt
    ```
  * Em um v√≠deo aleat√≥rio da pasta `videos/`:

    ```bash
    python -m reconhecimento --recognize --random --model yolov8n.pt
    ```

> **Observa√ß√£o**: o par√¢metro `--model` aponta para o arquivo `.pt` do YOLO (v8 ou v11) dispon√≠vel no diret√≥rio raiz. O modelo padr√£o √© `yolo11n.pt`.

### 2. Modo interativo

Simplesmente execute:

```bash
python -m reconhecimento
```

O menu interativo apresentar√° as op√ß√µes:

```
[1] - Capturar imagens
[2] - Treinar dataset
[3] - Executar reconhecimento
```

Basta digitar `1`, `2` ou `3` conforme desejado e seguir as instru√ß√µes na tela.

## üî¨ Suporte a GPU

**YOLOv8 e InsightFace suportam GPU, mas dependem do seu ambiente.**

### Como garantir o uso de GPU:

Instale o pacote `onnxruntime-gpu` no lugar de `onnxruntime`.

1. **Drivers NVIDIA** instalados e CUDA dispon√≠vel.
2. **PyTorch** instalado com CUDA.

   * Veja seu CUDA com `nvidia-smi`.
   * Exemplo para CUDA 11.7:

     ```bash
     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117
     ```
3. **MXNet** instalado na vers√£o CUDA correta:

   * Para CUDA 11.7:

     ```bash
     pip install mxnet-cu117
     ```
   * Para CPU apenas:

     ```bash
     pip install mxnet
     ```
4. Rode seu script normalmente. O console informar√° se GPU est√° ativa.

## Observa√ß√µes Finais

* Ajuste os paths dentro dos scripts se a estrutura de pastas for alterada.
* Para melhor desempenho em treinamento e infer√™ncia, instale drivers e suporte CUDA adequados.
* Logs de treinamento e arquivos gerados ficar√£o dentro da pasta `trainer/`.

---